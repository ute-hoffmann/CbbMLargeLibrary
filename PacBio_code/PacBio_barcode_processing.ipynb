{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c7cd1b",
   "metadata": {},
   "source": [
    "# Preparation of barcode to mutant variant assignment\n",
    "\n",
    "The CbbM combinatorial and saturational libraries were digested separately with single-cutter restriction enzymes. After some purification steps, DNA was sent to NGI in Uppsala for PacBio library preparation and sequencing.\n",
    "\n",
    "## Process PacBio sequencing results to assign barcodes to mutant variants\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "PacBio sequences were mapped using minimap2 v2.28 (r1209) and its CCS-specific preset to a 1,675 bp long template spanning the promoter region (Ptrc), coding sequence of cbbM(I) and a small region up- and downstream of the N20 barcode. The resulting sam-file was filtered for aligned reads with a mapping quality above 5 (MAPQ > 5) using the samtools v1.13 view command.\n",
    "\n",
    "`./minimap2/minimap2 -ax map-hifi ref_cbbM_onlyInsert.fa m84045_240523_204011_s1.fastq > alignment.sam`\n",
    "\n",
    "`samtools view alignment.sam -q 5 > alignment_onlyMapped.sam`\n",
    "\n",
    "minimap2 gave the following output: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486f0a9",
   "metadata": {},
   "source": [
    "[M::mm_idx_gen::0.001*3.24] collected minimizers\n",
    "[M::mm_idx_gen::0.004*3.03] sorted minimizers\n",
    "[M::main::0.004*3.01] loaded/built the index for 1 target sequence(s)\n",
    "[M::mm_mapopt_update::0.004*2.96] mid_occ = 50\n",
    "[M::mm_idx_stat] kmer size: 19; skip: 19; is_hpc: 0; #seq: 1\n",
    "[M::mm_idx_stat::0.004*2.93] distinct minimizers: 161 (100.00% are singletons); average occurrences: 1.000; average spacing: 10.404; total length: 1675\n",
    "[M::worker_pipeline::11.694*2.95] mapped 74228 sequences\n",
    "[M::worker_pipeline::21.712*3.10] mapped 74275 sequences\n",
    "[M::worker_pipeline::32.850*3.17] mapped 74267 sequences\n",
    "[M::worker_pipeline::52.027*3.17] mapped 74283 sequences\n",
    "[M::worker_pipeline::67.171*2.58] mapped 74273 sequences\n",
    "[M::worker_pipeline::88.953*2.70] mapped 74282 sequences\n",
    "[M::worker_pipeline::95.307*2.76] mapped 76924 sequences\n",
    "[M::worker_pipeline::113.167*2.83] mapped 80983 sequences\n",
    "[M::worker_pipeline::140.630*2.37] mapped 76552 sequences\n",
    "[M::worker_pipeline::155.093*2.37] mapped 75791 sequences\n",
    "[M::worker_pipeline::172.260*2.29] mapped 84966 sequences\n",
    "[M::worker_pipeline::201.381*2.14] mapped 76781 sequences\n",
    "[M::worker_pipeline::216.760*2.16] mapped 75404 sequences\n",
    "[M::worker_pipeline::246.265*2.07] mapped 75751 sequences\n",
    "[M::worker_pipeline::260.820*2.13] mapped 74410 sequences\n",
    "[M::worker_pipeline::290.399*2.01] mapped 74258 sequences\n",
    "[M::worker_pipeline::303.445*2.06] mapped 75417 sequences\n",
    "[M::worker_pipeline::325.591*2.02] mapped 80280 sequences\n",
    "[M::worker_pipeline::348.793*1.97] mapped 91360 sequences\n",
    "[M::main] Version: 2.28-r1209\n",
    "[M::main] CMD: ./minimap2/minimap2 -ax map-hifi ref_cbbM_onlyInsert.fa m84045_240523_204011_s1.fastq\n",
    "[M::main] Real time: 348.794 sec; CPU: 685.999 sec; Peak RSS: 1.933 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b564f546",
   "metadata": {},
   "source": [
    "Aligned reads were extracted from the resulting sam file and converted into a fasta format with a python 3.9.7 script (sam2fasta.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e318887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sam2fasta.py\n",
    "with open(\"alignment_onlyMapped.sam\") as sam_file:\n",
    "    with open(\"aligned_seq.fasta\", \"w\") as fasta_file:\n",
    "        for line in sam_file:\n",
    "            if line[0] == \"@\":\n",
    "                continue\n",
    "            else:\n",
    "                seq_name = line.split(\"\\t\")[0]\n",
    "                sequence = line.split(\"\\t\")[9]\n",
    "                fasta_file.write(\">\" + seq_name + \"\\n\" + sequence + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c89aeb",
   "metadata": {},
   "source": [
    "To extract coding sequences and barcodes from this file, cutadapt v3.5 was run using two different sets of paired adapters corresponding to the sequences exactly up- and downstream of the cbbM coding sequence and the N20 barcode, respectively. Untrimmed reads were discarded. \n",
    "\n",
    "`cutadapt -a ACTGAAACATCTTAATCATGCTAAGGAGGTTTTCTA...TCTAGAATCGCCGAAAGTAATTCAACTCCATTAA --discard-untrimmed -o CDS_trim.fasta aligned_seq.fasta > cutadapt_CDSreport.txt`\n",
    "\n",
    "`cutadapt -a TCTAGAATCGCCGAAAGTAATTCAACTCCATTAA...TCTAGATGCTTACTAGTTACCGCGGCCAGGCAT --discard-untrimmed -o barcode_trim.fasta aligned_seq.fasta 2> cutadapt_barcode_report.txt`\n",
    "\n",
    "A set of python 3.9.7 scripts were used to assign barcodes to coding sequences and translate the latter to protein sequences (extract_from_barcodeFasta.py, extract_from_CDS_Fasta.py). In the same step, the set of extracted barcodes was separated into three subsets according to the number of their occurrences. Furthermore, coding sequences translated into protein products shorter than 400 amino acids were discarded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "337af244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally: extract_from_barcodeFasta.py\n",
    "# Open file created by cutadapt, extract barcodes, discard barcodes < 15 nt or > 20 nt\n",
    "# save file with barcode, seqname, number of occurrences\n",
    "barcode_dict = {}\n",
    "\n",
    "with open(\"barcode_trim.fasta\") as barcode_file:\n",
    "    for line in barcode_file:\n",
    "        if line[0] == \">\":\n",
    "            seq_name = line.strip(\"\\n\")[1:]\n",
    "        else:\n",
    "            barcode = line.strip(\"\\n\")\n",
    "            if len(barcode) > 20 or len(barcode) < 15:\n",
    "                continue\n",
    "            else:\n",
    "                if barcode not in barcode_dict.keys():\n",
    "                    barcode_dict[barcode] = [1,[seq_name]]\n",
    "                else:\n",
    "                    barcode_dict[barcode][0] += 1\n",
    "                    barcode_dict[barcode][1].append(seq_name)\n",
    "\n",
    "with open(\"interm_file/barcode_occurrences_seqname.tsv\", \"w\") as barcode_file:\n",
    "    barcode_file.write(\"barcode\\toccurrences\\tseqname\\n\")\n",
    "    for barcode in barcode_dict.keys():\n",
    "        for seqname in barcode_dict[barcode][1]:\n",
    "            barcode_file.write(str(barcode) + \"\\t\" + str(barcode_dict[barcode][0]) + \"\\t\" + seqname + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d650e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went through first file\n",
      "counter is 50000\n",
      "counter is 100000\n",
      "counter is 150000\n",
      "counter is 200000\n",
      "counter is 250000\n",
      "counter is 300000\n",
      "counter is 350000\n",
      "counter is 400000\n",
      "counter is 450000\n",
      "counter is 500000\n",
      "counter is 550000\n",
      "counter is 600000\n",
      "counter is 650000\n",
      "counter is 700000\n",
      "counter is 750000\n",
      "counter is 800000\n",
      "counter is 850000\n",
      "counter is 900000\n",
      "counter is 950000\n",
      "counter is 1000000\n",
      "counter is 1050000\n",
      "counter is 1100000\n",
      "counter is 1150000\n",
      "counter is 1200000\n",
      "counter is 1250000\n",
      "counter is 1300000\n",
      "counter is 1350000\n",
      "counter is 1400000\n",
      "counter is 1450000\n",
      "counter is 1500000\n",
      "counter is 1550000\n",
      "counter is 1600000\n",
      "counter is 1650000\n",
      "counter is 1700000\n",
      "counter is 1750000\n",
      "counter is 1800000\n",
      "counter is 1850000\n",
      "counter is 1900000\n",
      "counter is 1950000\n",
      "counter is 2000000\n",
      "counter is 2050000\n",
      "counter is 2100000\n",
      "counter is 2150000\n",
      "counter is 2200000\n",
      "counter is 2250000\n",
      "counter is 2300000\n",
      "counter is 2350000\n",
      "counter is 2400000\n",
      "counter is 2450000\n",
      "counter is 2500000\n",
      "counter is 2550000\n"
     ]
    }
   ],
   "source": [
    "# originally: extract_from_CDS_Fasta.py\n",
    "# separate barcodes according to number of occurrences into 3 sets (save RAM later)\n",
    "# assign CDS to barcodes according to shared seqname (from cutadapt output file)\n",
    "# discard CDS shorter than 300 aa (unlikely to be relevant for us)\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def pad_seq(sequence):\n",
    "    \"\"\" Pad sequence to multiple of 3 with N \"\"\" # from https://stackoverflow.com/questions/53894575/how-can-i-fix-this-error-biopythonwarning-partial-codon-lensequence-not-a\n",
    "    remainder = len(sequence) % 3\n",
    "    return sequence if remainder == 0 else sequence + Seq('N' * (3 - remainder))\n",
    "\n",
    "seqnames_of_interest_occ1 = {}\n",
    "seqnames_of_interest_occ10 = {}\n",
    "seqnames_of_interest_rest = {}\n",
    "\n",
    "counter = 0\n",
    "with open(\"interm_file/barcode_occurrences_seqname.tsv\") as barcode_table:\n",
    "    line_one = True\n",
    "    for line in barcode_table:\n",
    "        if line_one:\n",
    "            line_one = False\n",
    "            continue\n",
    "        occurrences = int(line.strip(\"\\n\").split(\"\\t\")[1])\n",
    "        barcode = line.split(\"\\t\")[0]\n",
    "        seq = line.strip(\"\\n\").split(\"\\t\")[2]\n",
    "        if occurrences == 1:\n",
    "            seqnames_of_interest_occ1[seq] = barcode\n",
    "        if occurrences > 1 and occurrences < 11:\n",
    "            seqnames_of_interest_occ10[seq] = barcode\n",
    "        if occurrences > 10:\n",
    "            seqnames_of_interest_rest[seq] = barcode\n",
    "\n",
    "print(\"Went through first file\")\n",
    "\n",
    "with open(\"interm_file/barcode_CDS_1occ.tsv\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "with open(\"interm_file/barcode_CDS_10occ.tsv\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "with open(\"interm_file/barcode_CDS_rest.tsv\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "counter = 0\n",
    "with open(\"CDS_trim.fasta\") as CDS_file:\n",
    "        for line in CDS_file:\n",
    "            counter += 1\n",
    "            if counter % 50000 == 0:\n",
    "                print(\"counter is \" + str(counter))\n",
    "            if line[0] == \">\":\n",
    "                seq_name = line.strip(\"\\n\")[1:]\n",
    "            else:                \n",
    "                my_dna = Seq(pad_seq(line.strip(\"\\n\")))\n",
    "                my_aa = str(my_dna.translate()).split(\"*\")[0]\n",
    "                if len(my_aa) < 300:\n",
    "                    continue\n",
    "                if seq_name in seqnames_of_interest_occ1.keys():\n",
    "                    with open(\"interm_file/barcode_CDS_1occ.tsv\", \"a\") as f:\n",
    "                        f.write(seqnames_of_interest_occ1[seq_name] + \"\\t\" + my_aa + \"\\n\")\n",
    "                if seq_name in seqnames_of_interest_occ10.keys():\n",
    "                    with open(\"interm_file/barcode_CDS_10occ.tsv\", \"a\") as f:\n",
    "                        f.write(seqnames_of_interest_occ10[seq_name] + \"\\t\" + my_aa + \"\\n\")\n",
    "                if seq_name in seqnames_of_interest_rest.keys():\n",
    "                    with open(\"interm_file/barcode_CDS_rest.tsv\", \"a\") as f:\n",
    "                        f.write(seqnames_of_interest_rest[seq_name] + \"\\t\" + my_aa + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3877f7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clear RAM: delete dictionaries\n",
    "del seqnames_of_interest_occ1\n",
    "del seqnames_of_interest_occ10\n",
    "del seqnames_of_interest_rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73323fc",
   "metadata": {},
   "source": [
    "For barcodes occurring more than once, the assigned coding sequences were compared and the sequence occurring most frequently was used as consensus sequence. In case there were ties, these barcodes were omitted from future analysis (find_consensus_sequences.py and find_counsensus_sequences_over100.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94f767d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of barcodes to be checked: 177406\n",
      "9601 barcodes with ties and 0 barcodes with no most frequent CDS\n"
     ]
    }
   ],
   "source": [
    "# originally: find_consensus_sequences.py and find_counsensus_sequences_over100.py\n",
    "# for barcodes that occur between 2 and 10 times, find consensus sequence\n",
    "# assumes that longer CDS is more correct than shorter CDS (assumption that early stop codons are sequencing mistake)\n",
    "\n",
    "barcode_dict = {}\n",
    "\n",
    "with open(\"interm_file/barcode_CDS_10occ.tsv\") as barc_file:\n",
    "    for line in barc_file:\n",
    "        barcode = line.split(\"\\t\")[0]\n",
    "        CDS = line.strip(\"\\n\").split(\"\\t\")[1]\n",
    "        if barcode not in barcode_dict.keys():\n",
    "            barcode_dict[barcode] = [CDS]\n",
    "        else:\n",
    "            barcode_dict[barcode].append(CDS)\n",
    "\n",
    "with open(\"interm_file/barcode_CDS_rest.tsv\") as barc_file:\n",
    "    for line in barc_file:\n",
    "        barcode = line.split(\"\\t\")[0]\n",
    "        CDS = line.strip(\"\\n\").split(\"\\t\")[1]\n",
    "        if barcode not in barcode_dict.keys():\n",
    "            barcode_dict[barcode] = [CDS]\n",
    "        else:\n",
    "            barcode_dict[barcode].append(CDS)\n",
    "            \n",
    "print(\"Number of barcodes to be checked: \" + str(len(barcode_dict.keys())))\n",
    "\n",
    "with open(\"interm_file/barcode_CDS_consensus.tsv\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "with open(\"interm_file/barcode_CDS_ties.tsv\", \"w\") as f:\n",
    "    f.write(\"\")\n",
    "with_ties = 0\n",
    "no_long_CDS = 0\n",
    "for barcode in barcode_dict.keys():\n",
    "    CDS_dict = {}\n",
    "    max_count = 1\n",
    "    curr_count = 0\n",
    "    most_freq_CDS = []\n",
    "    for CDS in barcode_dict[barcode]:\n",
    "        if CDS not in CDS_dict.keys():\n",
    "            CDS_dict[CDS] = 1\n",
    "            curr_count = 1\n",
    "            if curr_count == max_count and CDS not in most_freq_CDS:\n",
    "                most_freq_CDS.append(CDS)\n",
    "        else:\n",
    "            CDS_dict[CDS] += 1\n",
    "            curr_count = CDS_dict[CDS]\n",
    "            if curr_count > max_count:\n",
    "                max_count = curr_count\n",
    "                most_freq_CDS = [CDS]\n",
    "            elif curr_count == max_count and CDS not in most_freq_CDS:\n",
    "                most_freq_CDS.append(CDS)\n",
    "    if not most_freq_CDS:\n",
    "        no_long_CDS += 1\n",
    "        continue\n",
    "    elif len(most_freq_CDS) == 1:\n",
    "        with open(\"interm_file/barcode_CDS_consensus.tsv\", \"a\") as f:\n",
    "            f.write(str(barcode) + \"\\t\" + most_freq_CDS[0] + \"\\n\")\n",
    "    else:\n",
    "        max_len_CDS = 0\n",
    "        longest_CDS = []\n",
    "        for CDS in most_freq_CDS:\n",
    "            curr_len_CDS = len(CDS)\n",
    "            if curr_len_CDS > max_len_CDS:\n",
    "                max_len_CDS = curr_len_CDS\n",
    "                longest_CDS = [CDS]\n",
    "            if curr_len_CDS == max_len_CDS:\n",
    "                longest_CDS.append(CDS)\n",
    "        if len(longest_CDS) > 1:\n",
    "            with_ties += 1\n",
    "            with open(\"interm_file/barcode_CDS_ties.tsv\", \"a\") as f:\n",
    "                for CDS in most_freq_CDS:\n",
    "                    f.write(str(barcode) + \"\\t\" + CDS + \"\\n\")\n",
    "        else:\n",
    "            with open(\"interm_file/barcode_CDS_consensus.tsv\", \"a\") as f:\n",
    "                f.write(str(barcode) + \"\\t\" + longest_CDS[0] + \"\\n\")\n",
    "            \n",
    "                \n",
    "print(str(with_ties) + \" barcodes with ties and \" + str(no_long_CDS) + \" barcodes with no most frequent CDS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb84b38",
   "metadata": {},
   "source": [
    "Identify barcodes which are to be expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc1ccaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1805\n",
      "16200\n"
     ]
    }
   ],
   "source": [
    "# originally: create_table_expected_mutations.py\n",
    "# creates table of barcodes which are to be expected in library\n",
    "aa_dict = \"ARNDCEQGHILKMFPSTWYV\"\n",
    "\n",
    "dict_expected_mutations = {}\n",
    "with open(\"input/expected_saturational_mutations.tsv\") as f: \n",
    "    for line in f:\n",
    "        aa_pos = line.strip(\"\\n\")\n",
    "        WT_aa = aa_pos[0]\n",
    "        for aa in aa_dict:\n",
    "            if aa == WT_aa:\n",
    "                continue\n",
    "            else:\n",
    "                dict_expected_mutations[aa_pos + aa] = 0\n",
    "                \n",
    "with open(\"saturational_mutations.tsv\", \"w\") as f:\n",
    "    for mut in dict_expected_mutations.keys():\n",
    "        f.write(str(mut) + \"\\n\")\n",
    "print(len(dict_expected_mutations.keys()))\n",
    "\n",
    "combinatorial_dict = {}\n",
    "with open(\"input/expected_combinatorial_mutations.tsv\") as f:\n",
    "    for line in f: \n",
    "        aa_pos = line.split(\"\\t\")[0]\n",
    "        possible_aa = line.strip(\"\\n\").split(\"\\t\")[1].split(\",\")\n",
    "        combinatorial_dict[aa_pos] = possible_aa\n",
    "\n",
    "dict_expected_combi = {}\n",
    "list_combi = [\"H127\", \"M140\", \"K247\", \"H251\", \"V323\", \"Q392\", \"S432\"]\n",
    "H_combis = []\n",
    "for H_aa in combinatorial_dict[\"H141\"]:\n",
    "    if H_aa == \"H\":\n",
    "        H_combis.append(\"\")\n",
    "    else:\n",
    "        H_combis.append(\"H141\" + H_aa + \",\")\n",
    "M_combis = []\n",
    "for M_aa in combinatorial_dict[\"M154\"]:\n",
    "    if M_aa == \"M\": \n",
    "        for H in H_combis:\n",
    "            M_combis.append(H)    \n",
    "    else:\n",
    "        for H in H_combis:\n",
    "            M_combis.append(H + \"M154\" + M_aa + \",\")\n",
    "K_combis = []\n",
    "for K_aa in combinatorial_dict[\"K261\"]:\n",
    "    if K_aa == \"K\": \n",
    "        for M in M_combis:        \n",
    "            K_combis.append(M)\n",
    "    else: \n",
    "        for M in M_combis:        \n",
    "            K_combis.append(M + \"K261\" + K_aa + \",\")\n",
    "H_combis = []\n",
    "for H_aa in combinatorial_dict[\"H265\"]:\n",
    "    if H_aa == \"H\": \n",
    "        for K in K_combis:\n",
    "            H_combis.append(K)\n",
    "    else:\n",
    "        for K in K_combis:\n",
    "            H_combis.append(K +\"H265\" + H_aa + \",\")\n",
    "V_combis = []\n",
    "for V_aa in combinatorial_dict[\"V337\"]:\n",
    "    if V_aa == \"V\":\n",
    "        for H in H_combis:\n",
    "            V_combis.append(H)\n",
    "    else:\n",
    "        for H in H_combis:\n",
    "            V_combis.append(H +\"V337\" + V_aa + \",\")\n",
    "Q_combis = []\n",
    "for Q_aa in combinatorial_dict[\"Q406\"]:\n",
    "    if Q_aa == \"Q\": \n",
    "        for V in V_combis:\n",
    "            Q_combis.append(V)\n",
    "    else:\n",
    "        for V in V_combis:\n",
    "            Q_combis.append(V + \"Q406\" + Q_aa + \",\")\n",
    "S_combis = []\n",
    "for S_aa in combinatorial_dict[\"S446\"]:\n",
    "    if S_aa == \"S\":\n",
    "        for Q in Q_combis:\n",
    "            S_combis.append(Q)\n",
    "    else:\n",
    "        for Q in Q_combis:\n",
    "            S_combis.append(Q + \"S446\" + S_aa + \",\")\n",
    "for combi in S_combis:\n",
    "    if combi == \"\":\n",
    "        dict_expected_combi[\"WT,\"] = 1\n",
    "        continue\n",
    "    dict_expected_combi[combi] = 1\n",
    "                                \n",
    "with open(\"combinatorial_mutations.tsv\", \"w\") as f:\n",
    "    for mut in dict_expected_combi.keys():\n",
    "        f.write(str(mut)[:-1] + \"\\n\")\n",
    "print(len(dict_expected_combi.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2d60ff",
   "metadata": {},
   "source": [
    "In a final step, all barcodes were combined into one file, amino acid exchanges compared to the CbbM(I) sequence were determined and the combination of barcodes and assigned mutations were formatted to be compatible with downstream applications (process_all_sequences.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b2869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 1 occ barcodes\n",
      "total: 67793\n",
      "With consensus sequences\n",
      "total: 235598\n",
      "Expected mutant variants: 17983\n",
      "3518 mutant variants excluded due to length constraints\n",
      "Mutant variants not expected, covered by more than one barcode: 1298, for instance: ['G395V,STOP395', 'H141L,M154S,K261E,H265A,V337A,F405S,Q406K,N407T,STOP407', 'A83V,H141L,M154S,K261E,H265R,V337S,Q406D,S446I', 'K261F,Q406P,N407E,G409R,H410A,G411R,N412E,V413R,I414N,STOP414', 'Q406P,N407E,G409R,H410A,G411R,N412E,V413R,I414N,STOP414', 'STOP360', 'M326R,T347C', 'M154E,G395V,STOP395', 'A295G,V297G,T298D,T299H,A300C,R301T,R302A,E303R,F304V,D306R,T307Y,F308L,H310A,F311L,H312S,R313S,A314R,H316T,G317W,A318G,V319S,T320H,S321I,Y322L,STOP322']\n",
      "Found barcodes for expected mutant variants: 205150, for number mutant variants: 17839\n",
      "Variants not found: ['H141V,M154E,K261A', 'H141L,M154S,K261E,H265K', 'H141L,K261F,H265R', 'H141L,M154A,K261F,H265E', 'M154K,H265K,V337A', 'M154K,K261D,H265K,V337A', 'H141L,K261F,H265K,V337A', 'H141V,M154S,K261D,H265K,V337S', 'H141L,M154S,K261D,H265K,V337S', 'H141V,M154A,K261D,Q406E', 'H141L,M154E,K261E,Q406E', 'H141L,M154D,K261A,H265A,Q406E', 'M154E,K261F,H265A,Q406E', 'M154A,K261E,H265K,V337A,Q406E', 'M154A,K261E,H265A,V337A,Q406E', 'K261A,H265E,V337A,Q406E', 'H141L,M154A,K261D,Q406D', 'M154K,H265K,Q406D', 'H141L,M154D,K261F,H265E,Q406D', 'M154A,V337A,Q406D', 'H141L,M154D,K261F,H265A,V337A,Q406D', 'H141L,M154A,K261E,H265E,V337A,Q406D', 'M154K,V337S,Q406D', 'H141V,M154K,K261A,H265K,V337S,Q406D', 'H141V,M154A,S446A', 'M154D,K261F,S446A', 'H141L,M154K,K261A,H265K,S446A', 'H141V,M154K,V337A,S446A', 'H141L,M154K,K261A,H265K,V337A,S446A', 'H141V,M154A,K261A,H265A,V337A,S446A', 'M154K,K261E,H265A,V337A,S446A', 'H141L,M154E,H265R,V337A,S446A', 'M154A,K261E,H265A,V337S,S446A', 'H141L,M154D,K261A,H265E,V337S,S446A', 'M154K,K261A,H265K,Q406E,S446A', 'H141L,M154D,K261E,H265K,Q406E,S446A', 'H141L,K261E,H265R,Q406E,S446A', 'M154E,K261E,H265E,Q406E,S446A', 'M154D,K261F,V337A,Q406E,S446A', 'H141V,M154S,K261F,V337A,Q406E,S446A', 'M154D,K261E,H265K,V337S,Q406E,S446A', 'H141L,M154D,H265A,V337S,Q406E,S446A', 'H141V,M154E,K261A,H265R,V337S,Q406E,S446A', 'H141L,M154E,K261E,Q406D,S446A', 'H141L,M154A,H265K,Q406D,S446A', 'M154D,K261D,H265A,Q406D,S446A', 'H141V,M154A,K261F,V337A,Q406D,S446A', 'H141L,K261A,H265R,V337A,Q406D,S446A', 'M154D,K261D,H265K,V337S,Q406D,S446A', 'H141L,M154E,K261F,S446I', 'H141L,M154A,K261E,S446I', 'H141V,M154E,H265K,S446I', 'H141L,M154D,H265K,S446I', 'H141V,M154A,H265K,S446I', 'H141L,M154A,H265K,S446I', 'H141V,M154A,K261F,H265K,S446I', 'H141V,M154E,H265A,S446I', 'H141L,M154K,K261D,H265A,S446I', 'H141L,M154E,H265R,S446I', 'H141L,M154K,K261E,H265R,S446I', 'H141V,M154E,H265E,S446I', 'H141L,M154E,H265E,S446I', 'H141L,K261F,H265E,S446I', 'H141V,M154A,K261F,H265E,S446I', 'V337A,S446I', 'M154K,V337A,S446I', 'H141L,M154K,V337A,S446I', 'H141L,M154S,V337A,S446I', 'H141V,K261D,H265K,V337A,S446I', 'H141V,M154E,K261D,H265K,V337A,S446I', 'H141V,K261A,H265K,V337A,S446I', 'H141V,M154D,K261D,H265A,V337A,S446I', 'H141L,M154K,K261D,H265A,V337A,S446I', 'H141L,K261D,H265R,V337A,S446I', 'H141L,M154E,K261A,H265R,V337A,S446I', 'H141V,M154E,K261D,H265E,V337A,S446I', 'H141V,M154S,K261F,H265K,V337S,S446I', 'H141L,M154E,K261E,H265K,V337S,S446I', 'M154K,K261A,H265A,V337S,S446I', 'H141V,M154S,K261A,H265R,V337S,S446I', 'H141L,K261F,H265R,V337S,S446I', 'H141V,M154A,K261A,H265E,V337S,S446I', 'H141V,M154D,K261F,H265E,V337S,S446I', 'H141L,M154S,K261F,H265E,V337S,S446I', 'H141V,Q406E,S446I', 'H141L,M154S,K261F,Q406E,S446I', 'H141L,K261D,H265K,Q406E,S446I', 'H141V,M154A,K261D,H265K,Q406E,S446I', 'M154A,K261A,H265K,Q406E,S446I', 'M154E,K261F,H265K,Q406E,S446I', 'M154S,K261F,H265K,Q406E,S446I', 'H141L,M154E,H265A,Q406E,S446I', 'H141V,M154D,H265A,Q406E,S446I', 'M154D,K261F,H265A,Q406E,S446I', 'H141L,K261D,H265R,Q406E,S446I', 'H141L,M154S,H265E,Q406E,S446I', 'H141V,M154D,K261E,V337A,Q406E,S446I', 'H141L,M154E,K261F,H265K,V337A,Q406E,S446I', 'M154E,K261E,H265K,V337A,Q406E,S446I', 'M154K,K261D,H265R,V337A,Q406E,S446I', 'H141V,M154D,K261E,H265R,V337A,Q406E,S446I', 'M154K,K261D,V337S,Q406E,S446I', 'H141V,K261F,H265K,V337S,Q406E,S446I', 'H141L,M154D,Q406D,S446I', 'H141V,M154S,Q406D,S446I', 'H141L,M154A,Q406D,S446I', 'H141V,M154D,K261A,Q406D,S446I', 'H141V,M154D,H265K,Q406D,S446I', 'M154E,K261D,H265K,Q406D,S446I', 'H141L,M154S,K261D,H265A,Q406D,S446I', 'M154D,K261F,H265A,Q406D,S446I', 'H141L,M154K,H265E,Q406D,S446I', 'H141L,M154E,K261F,H265E,Q406D,S446I', 'H141L,M154A,V337A,Q406D,S446I', 'H265K,V337A,Q406D,S446I', 'M154K,K261D,H265K,V337A,Q406D,S446I', 'M154S,V337S,Q406D,S446I', 'H141L,M154E,H265K,V337S,Q406D,S446I', 'M154E,K261D,H265K,V337S,Q406D,S446I', 'H141V,M154A,K261F,H265K,V337S,Q406D,S446I', 'H141L,K261E,H265K,V337S,Q406D,S446I', 'H141L,M154E,K261E,H265A,V337S,Q406D,S446I', 'H141V,K261E,H265R,V337S,Q406D,S446I', 'M154A,K261F,H265E,V337S,Q406D,S446I', 'M154D,K261D,S446T', 'H141L,M154S,H265K,S446T', 'H141V,M154A,H265K,S446T', 'H141V,M154A,K261D,H265A,V337A,S446T', 'M154K,K261A,H265R,V337A,S446T', 'H265K,Q406E,S446T', 'H141L,K261D,H265A,Q406E,S446T', 'H141L,M154E,K261F,H265A,Q406E,S446T', 'H141L,M154E,K261F,V337S,Q406E,S446T', 'H141V,M154K,K261E,V337S,Q406E,S446T', 'H141L,M154A,H265K,V337S,Q406E,S446T', 'H141V,M154E,Q406D,S446T', 'M154K,K261A,H265R,Q406D,S446T', 'H141V,M154S,K261F,H265E,Q406D,S446T', 'M154E,K261E,V337A,Q406D,S446T', 'M154D,K261E,V337A,Q406D,S446T', 'H141L,M154A,K261F,H265K,V337A,Q406D,S446T', 'H141V,M154A,K261D,H265E,V337A,Q406D,S446T', 'H141V,M154K,K261F,H265A,V337S,Q406D,S446T', 'H141L,M154D,K261E,H265A,V337S,Q406D,S446T']\n"
     ]
    }
   ],
   "source": [
    "# originally: process_all_sequences.py\n",
    "# combines all barcodes and mutations in one file\n",
    "# compares to list of expected mutant variants - saves this into separate file\n",
    "barc_dict = {}\n",
    "\n",
    "total = 0\n",
    "with open(\"interm_file/barcode_CDS_1occ.tsv\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "        barcode = line.split(\"\\t\")[0]\n",
    "        seq = line.strip(\"\\n\").split(\"\\t\")[1]\n",
    "        barc_dict[barcode] = seq\n",
    "print(\"after 1 occ barcodes\\ntotal: \" + str(total))\n",
    "\n",
    "with open(\"interm_file/barcode_CDS_consensus.tsv\") as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "        barcode = line.split(\"\\t\")[0]\n",
    "        seq = line.strip(\"\\n\").split(\"\\t\")[1]\n",
    "        barc_dict[barcode] = seq\n",
    "print(\"With consensus sequences\\ntotal: \" + str(total))\n",
    "\n",
    "with open(\"output/all_barcodes_complete_CDS.tsv\", \"w\") as f:\n",
    "    for barcode in barc_dict:\n",
    "        f.write(barcode + \"\\t\" + barc_dict[barcode] + \"\\n\")\n",
    "\n",
    "expected_mut = {}\n",
    "with open(\"saturational_mutations.tsv\") as f:\n",
    "    for line in f:\n",
    "        expected_mut[line.strip(\"\\n\")] = 1\n",
    "with open(\"combinatorial_mutations.tsv\") as f:\n",
    "    for line in f:\n",
    "        expected_mut[line.strip(\"\\n\")] = 1\n",
    "print(\"Expected mutant variants: \" + str(len(expected_mut.keys())))\n",
    "found_expected_mut_variants = 0\n",
    "found_exp_mut_variants = {}\n",
    "with open(\"output/expected_mutations_barcodes.tsv\", \"w\") as f2:\n",
    "    f2.write(\"\")\n",
    "original_seq = \"MWSHPQFEKGSGSGSDQSNRYANLNLKEEDLIKNGKHLLVAYKLIPAKGHGFLEVAAHVAAESSTGTNVEVSTTDDFTRGVDALVYEIDETAFGDDPVKGGGLFKVAYPVELFDPNLTDGTYNISHMWSLILGNNQGMGDHQGLRMLDFLVPEMMVRKFDGPSANISNLWKVLGRPETDGGYIAGTIIKPKLGLRPEPFAKACYDFWLGGDFIKNDEPQANQPFCPMEVVMPKVAEAMDRAQQATGQAKLFSANITADYYKEMIHRGDFVLETFAKYNSASHVAFLVDGFVTGPAGVTTARREFPDTFLHFHRAGHGAVTSYKSPMGMDPLCYMKLVRLMGASGMHTGTMGYGKMEGHGKETVLAYMLERDECQGPYFYQKWYGMKATTPIISGGMNALRLPGFFQNLGHGNVINTCGGGAFGHIDSPAAGGISLRQAYDCWKSGSDPIEYAKTHKEFARAFESFPKDGDKLFAGWREKLGVHK\"\n",
    "mutation_to_barc = {}\n",
    "with open(\"output/all_barcodes_mutations.tsv\", \"w\") as f:\n",
    "    for barcode in barc_dict:\n",
    "        mutation_code = \"\"\n",
    "        seq = barc_dict[barcode]\n",
    "        if len(seq) > len(original_seq):\n",
    "            for index in range(len(seq)):\n",
    "                if index == len(original_seq):\n",
    "                    mutation_code += (\"X\" + str(index) + seq[index] + \",\")\n",
    "                    break\n",
    "                if original_seq[index] == seq[index]:\n",
    "                    continue\n",
    "                else:\n",
    "                    mutation_code += (original_seq[index] + str(index+1) + seq[index] + \",\")\n",
    "        else:\n",
    "            for index in range(len(original_seq)):\n",
    "                if index == len(seq):\n",
    "                    mutation_code += \"STOP\" + str(index) + \",\"\n",
    "                    break\n",
    "                if original_seq[index] == seq[index]:\n",
    "                    continue\n",
    "                else:\n",
    "                    mutation_code += (original_seq[index] + str(index+1) + seq[index] + \",\")\n",
    "        if mutation_code == \"\":\n",
    "            mutation_code = \"WT,\"\n",
    "        f.write(barcode + \"\\t\" + mutation_code[:-1] + \"\\n\")\n",
    "        if mutation_code[:-1] not in mutation_to_barc.keys():\n",
    "            mutation_to_barc[mutation_code[:-1]] = [barcode]\n",
    "        else:\n",
    "            mutation_to_barc[mutation_code[:-1]].append(barcode)\n",
    "        with open(\"output/expected_mutations_barcodes.tsv\", \"a\") as f2:\n",
    "            if mutation_code[:-1] in expected_mut.keys():\n",
    "                found_expected_mut_variants += 1\n",
    "                found_exp_mut_variants[mutation_code[:-1]] = 1\n",
    "                f2.write(barcode + \"\\t\" + mutation_code[:-1] + \"\\n\")\n",
    "                \n",
    "mutations_covered = []\n",
    "length_constraints = 0\n",
    "with open(\"output/unfiltered_barcodes.fasta\", \"w\") as f:\n",
    "    for mut in mutation_to_barc.keys():\n",
    "        if len(str(mut)) > 190: # featureCounts upper limit is 199 characters\n",
    "            length_constraints += 1\n",
    "            continue\n",
    "        if mut in expected_mut.keys():\n",
    "            for i in range(len(mutation_to_barc[mut])):\n",
    "                f.write(\">\" + str(mut) + \"|\" + str(i+1) + \"\\n\" + mutation_to_barc[mut][i] + \"\\n\")\n",
    "        else:\n",
    "            if len(mutation_to_barc[mut]) > 1:\n",
    "                mutations_covered += [mut]\n",
    "                for i in range(len(mutation_to_barc[mut])):\n",
    "                    f.write(\">\" + str(mut) + \"|\" + str(i+1) + \"\\n\" + mutation_to_barc[mut][i] + \"\\n\")\n",
    "print(str(length_constraints) + \" mutant variants excluded due to length constraints\")\n",
    "print(\"Mutant variants not expected, covered by more than one barcode: \" + str(len(mutations_covered)) + \", for instance: \" + str(mutations_covered[1:10]))\n",
    "                    \n",
    "print(\"Found barcodes for expected mutant variants: \" + str(found_expected_mut_variants) + \", for number mutant variants: \" + str(len(found_exp_mut_variants.keys())))\n",
    "\n",
    "not_found = []\n",
    "for mut in expected_mut.keys():\n",
    "    if mut not in found_exp_mut_variants.keys():\n",
    "        not_found.append(mut)\n",
    "\n",
    "print(\"Variants not found: \" + str(not_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ef810",
   "metadata": {},
   "source": [
    "## Identify barcode subset for Nextflow analysis\n",
    "\n",
    "Run Nextflow once with unfiltered_barcodes.fasta, then select\n",
    "Also check for other mut variants than WT if they really need that many barcodes (25 should be alright?).\n",
    "Approx. 500 barcodes for WT, of which many are detected less than x times.\n",
    "Also, for mapping: reduce library to barcodes which were identified in all_counts.tsv (mapping of Illumina data from first large library cultivation)\n",
    "For further analyses, mutant variants which were not part of the originally designed library were only kept if they were represented by at least two barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd35499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All different mutant variants in all_counts.tsv (regardless of if counts): 19137\n",
      "Mutant variants with counts > 30: 14617\n",
      "Number mutant variants with redundancy: 8968\n",
      "All barcodes with counts > 30: 32549\n",
      "Mutant variants with more than 30 barcodes: 1, e.g.: ['WT']\n",
      "Number mutations not expected with counts above 30: 288\n",
      "Number mutations not expected with counts above 30 and more than 1 barcode: 34\n",
      "['F405S,Q406R,N407T,STOP407', 'M326F,T347C', 'H141V,M154E,K261F,H265K,V337S,STOP338', 'H141V,M154K,K261E,H265A,Q406D,STOP407', 'H141V,M154S,K261D,H265A,H410T,N412T,STOP412', 'H141L,M154A,K261E,H265A,V337S,H410T,N412T,STOP412', 'M154A,K261E,H265A,H410T,N412T,STOP412', 'H141L,M154K,K261A,V337S,R338A,STOP338', 'H141V,M154S,K261A,H265E,H410T,N412T,STOP412']\n",
      "Number mutations expected with counts above 50: 14329\n",
      "That gives in total 31981 barcodes to write.\n"
     ]
    }
   ],
   "source": [
    "# Check all_counts.tsv for which barcodes were identified by Illumina sequencing in Synechocystis library\n",
    "# discard al barcodes which were not found in the Synechocystis library\n",
    "# \"WT\" has many many many barcodes (>100) - only keep 25 barcodes which were scored highest\n",
    "# if mutant variant is not in the set of expected barcodes: only keep variant in library if more than one\n",
    "# barcode is assigned to mutant variant and detected by Illumina sequencing\n",
    "\n",
    "all_counts_mutations = {} # just collecting which mutant variants are in file\n",
    "all_counts_mut_with_counts = {} # dictionary with barcodes assigned to each mutant variant\n",
    "all_barcodes_with_counts = {} # all barcodes and how often they were counted\n",
    "number_muts_with_redundancy = 0\n",
    "first_line = True\n",
    "with open(\"input/all_counts.tsv\") as f: \n",
    "    for line in f:\n",
    "        if first_line:\n",
    "            first_line = False\n",
    "            continue\n",
    "        split_line = line.strip(\"\\n\").split(\"\\t\")\n",
    "        barcode_name = split_line[0]\n",
    "        mutant_variant = split_line[1]\n",
    "        all_counts_mutations[mutant_variant] = 1\n",
    "        col_sum = 0\n",
    "        for col in split_line[2:]:\n",
    "            col_sum += int(col)\n",
    "        if col_sum > 30:\n",
    "            if mutant_variant not in all_counts_mut_with_counts.keys():\n",
    "                all_counts_mut_with_counts[mutant_variant] = [barcode_name]\n",
    "            else:\n",
    "                all_counts_mut_with_counts[mutant_variant].append(barcode_name)\n",
    "            if barcode_name not in all_barcodes_with_counts.keys():\n",
    "                all_barcodes_with_counts[barcode_name] = col_sum\n",
    "            else:\n",
    "                all_barcodes_with_counts[barcode_name] += col_sum\n",
    "                \n",
    "                \n",
    "numbers = []    \n",
    "mutations = []\n",
    "for mut in all_counts_mut_with_counts.keys():\n",
    "    numbers.append(len(all_counts_mut_with_counts[mut]))\n",
    "    mutations.append(str(mut))\n",
    "    if len(all_counts_mut_with_counts[mut]) > 1:\n",
    "        number_muts_with_redundancy += 1\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(mutations, numbers)\n",
    "df.to_csv(\"numbers.csv\")\n",
    "        \n",
    "print(\"All different mutant variants in all_counts.tsv (regardless of if counts): \" + str(len(all_counts_mutations.keys())))\n",
    "print(\"Mutant variants with counts > 30: \" + str(len(all_counts_mut_with_counts.keys())))\n",
    "print(\"Number mutant variants with redundancy: \" + str(number_muts_with_redundancy))\n",
    "print(\"All barcodes with counts > 30: \" + str(len(all_barcodes_with_counts.keys())))\n",
    "\n",
    "expected_mutations = {}\n",
    "with open(\"combinatorial_mutations.tsv\") as f:\n",
    "    for line in f:\n",
    "        expected_mutations[line.strip(\"\\n\")] = 0\n",
    "with open(\"saturational_mutations.tsv\") as f:\n",
    "    for line in f:\n",
    "        expected_mutations[line.strip(\"\\n\")] = 0\n",
    "\n",
    "barcodes_to_write = []\n",
    "mutants_written = []\n",
    "identify_most_abundant_barcodes = []\n",
    "for key in all_counts_mut_with_counts.keys():\n",
    "    if len(all_counts_mut_with_counts[key]) > 30:\n",
    "        identify_most_abundant_barcodes.append(str(key))\n",
    "        barcode_abundance = []\n",
    "        mutants_written.append(key)\n",
    "        for barcode in all_counts_mut_with_counts[key]:\n",
    "            barcode_abundance.append(all_barcodes_with_counts[barcode])\n",
    "        all_above = sorted(barcode_abundance)[-30]\n",
    "        for barcode in all_counts_mut_with_counts[key]:\n",
    "            if all_barcodes_with_counts[barcode] > all_above-1:\n",
    "                barcodes_to_write.append(barcode)\n",
    "\n",
    "print(\"Mutant variants with more than 30 barcodes: \" + str(len(identify_most_abundant_barcodes)) + \", e.g.: \" + str(identify_most_abundant_barcodes))\n",
    "    \n",
    "unknown_muts_with_counts = 0\n",
    "unknown_muts_with_counts_more_than_one_barc = {}\n",
    "known_muts_with_counts = {}\n",
    "mutantvariants_to_include = []\n",
    "for mut in all_counts_mut_with_counts.keys():\n",
    "    if mut in mutants_written:\n",
    "        if mut not in expected_mutations.keys():\n",
    "            unknown_muts_with_counts_more_than_one_barc[mut] = 1\n",
    "            unknown_muts_with_counts += 1\n",
    "        else:\n",
    "            known_muts_with_counts[mut] = 1\n",
    "        mutantvariants_to_include.append(mut)\n",
    "        continue\n",
    "    if mut not in expected_mutations.keys():\n",
    "        unknown_muts_with_counts += 1\n",
    "        if len(all_counts_mut_with_counts[mut]) > 1:\n",
    "            barcodes_to_write += all_counts_mut_with_counts[mut]\n",
    "            unknown_muts_with_counts_more_than_one_barc[mut] = 1\n",
    "            mutantvariants_to_include.append(str(mut))\n",
    "    else:\n",
    "        known_muts_with_counts[mut] = 1\n",
    "        barcodes_to_write += all_counts_mut_with_counts[mut]\n",
    "        mutantvariants_to_include.append(str(mut))\n",
    "        \n",
    "print(\"Number mutations not expected with counts above 30: \" + str(unknown_muts_with_counts))\n",
    "print(\"Number mutations not expected with counts above 30 and more than 1 barcode: \" + str(len(unknown_muts_with_counts_more_than_one_barc.keys())))\n",
    "print(list(unknown_muts_with_counts_more_than_one_barc.keys())[1:10])\n",
    "print(\"Number mutations expected with counts above 50: \" + str(len(known_muts_with_counts.keys())))\n",
    "print(\"That gives in total \" + str(len(barcodes_to_write)) + \" barcodes to write.\")\n",
    "\n",
    "mut_barcode_dict = {}\n",
    "with open(\"output/unfiltered_barcodes.fasta\") as f:\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            mutant = line.strip(\"\\n\")[1:]\n",
    "        else:\n",
    "            barcode = line.strip(\"\\n\")\n",
    "            if mutant not in mut_barcode_dict.keys():\n",
    "                mut_barcode_dict[mutant] = barcode\n",
    "            else:\n",
    "                print(mutant + \" already encountered - something is wrong...\")\n",
    "\n",
    "with open(\"output/selected_barcodes_Nextflow.fa\", \"w\") as f:\n",
    "    for mut in barcodes_to_write:\n",
    "        f.write(\">\" + mut + \"\\n\" + mut_barcode_dict[mut] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4651c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31981\n",
      "31981\n"
     ]
    }
   ],
   "source": [
    "dict_barcodes = {}\n",
    "dict_barcodes2 = {}\n",
    "total = 0\n",
    "with open(\"output/selected_barcodes_Nextflow.fa\") as f: \n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            total += 1\n",
    "            name = line.strip(\"\\n\").strip(\">\")\n",
    "            mut = line.strip(\"\\n\").strip(\">\").split(\"|\")[0]\n",
    "            if mut in dict_barcodes.keys():\n",
    "                dict_barcodes[mut] += 1\n",
    "            else:\n",
    "                dict_barcodes[mut] = 1\n",
    "        else:\n",
    "            barcode = line.strip(\"\\n\")\n",
    "            if name in dict_barcodes2.keys():\n",
    "                print(name + \" occurred twice?\")\n",
    "            dict_barcodes2[name] = barcode        \n",
    "         \n",
    "print(total)\n",
    "print(len(list(dict_barcodes2.keys())))\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(dict_barcodes, orient=\"index\")\n",
    "df.to_csv(\"output/selected_barcodes_count.csv\")\n",
    "df2 = pd.DataFrame.from_dict(dict_barcodes2, orient=\"index\")\n",
    "df2.to_csv(\"output/selected_barcodes_seq.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2620e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
